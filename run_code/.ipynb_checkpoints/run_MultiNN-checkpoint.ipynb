{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wafer map pattern classification using MultiNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T03:57:37.787145Z",
     "start_time": "2021-03-22T03:57:37.781154Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, MaxPooling2D, Concatenate\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T03:57:38.020612Z",
     "start_time": "2021-03-22T03:57:38.010610Z"
    }
   },
   "outputs": [],
   "source": [
    "DIM = 64\n",
    "REPLICATION = 10\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCH = 1000\n",
    "TRAIN_SIZE_LIST = [500, 5000, 50000, 162946]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T03:57:38.020612Z",
     "start_time": "2021-03-22T03:57:38.010610Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T03:59:40.528753Z",
     "start_time": "2021-03-22T03:59:39.637132Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/X_MFE.pickle', 'rb') as f:\n",
    "    X_mfe = pickle.load(f)\n",
    "with open('../data/X_CNN_64.pickle', 'rb') as f:\n",
    "    X_cnn = pickle.load(f)\n",
    "with open('../data/y.pickle', 'rb') as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multiNN():\n",
    "    mfe_input = Input(shape=(59,))\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, pooling='avg')\n",
    "    concat = Concatenate()([mfe_input, base_model.output])\n",
    "    dense_1 = Dense(128, activation='relu')(concat)\n",
    "    dense_2 = Dense(128, activation='relu')(dense_1)\n",
    "    prediction = Dense(9, activation='softmax')(dense_2)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[mfe_input, base_model.input], outputs=prediction)\n",
    "    model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics='accuracy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T03:59:53.065733Z",
     "start_time": "2021-03-22T03:59:40.727700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stack wafer maps as 3 channels to correspond with RGB channels.\n",
    "X_cnn = (X_cnn - 0.5) * 2\n",
    "X_cnn_stacked = np.repeat(X_cnn, 3, -1)\n",
    "y_onehot = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REP_ID = 0\n",
    "RAN_NUM = 27407 + REP_ID\n",
    "\n",
    "for TRAIN_SIZE_ID in range(4):\n",
    "    TRAIN_SIZE = TRAIN_SIZE_LIST[TRAIN_SIZE_ID]\n",
    "\n",
    "    X_trnval_cnn, X_tst_cnn, y_trnval, y_tst =  train_test_split(X_cnn_stacked, y_onehot, \n",
    "                                                         test_size=10000, random_state=RAN_NUM)\n",
    "    X_trnval_mfe, X_tst_mfe =  train_test_split(X_mfe, \n",
    "                                                         test_size=10000, random_state=RAN_NUM)\n",
    "    # Randomly sample train set for evaluation at various train set size\n",
    "    if TRAIN_SIZE == X_trnval_mfe.shape[0]:\n",
    "        pass\n",
    "    else:\n",
    "        X_trnval_cnn, _, y_trnval, _ = train_test_split(X_trnval_cnn, y_trnval, \n",
    "                                                    train_size=TRAIN_SIZE, random_state=RAN_NUM)\n",
    "        X_trnval_mfe, _, = train_test_split(X_trnval_mfe, \n",
    "                                                    train_size=TRAIN_SIZE, random_state=RAN_NUM)\n",
    "        \n",
    "    # Get unique labels in training set. Some labels might not appear in small training set.\n",
    "    labels = np.unique(np.argmax(y_trnval, 1))\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_trnval_mfe_scaled = scaler.fit_transform(X_trnval_mfe)\n",
    "    X_tst_mfe_scaled = scaler.transform(X_tst_mfe)\n",
    "\n",
    "    model = build_multiNN()\n",
    "\n",
    "    log = model.fit([X_trnval_mfe_scaled, X_trnval_cnn], y_trnval, validation_split=0.2, \n",
    "                  epochs=MAX_EPOCH, callbacks=[early_stopping], verbose=0)\n",
    "    y_trnval_hat= model.predict([X_trnval_mfe_scaled, X_trnval_cnn])\n",
    "    y_tst_hat= model.predict([X_tst_mfe_scaled, X_tst_cnn])\n",
    "\n",
    "    macro = f1_score(np.argmax(y_tst, 1), np.argmax(y_tst_hat, 1), labels=labels, average='macro')\n",
    "    micro = f1_score(np.argmax(y_tst, 1), np.argmax(y_tst_hat, 1), labels=labels, average='micro')\n",
    "    cm = confusion_matrix(np.argmax(y_tst, 1), np.argmax(y_tst_hat, 1))\n",
    "\n",
    "    filename = '../result/WMPC_MultiNN_'+str(TRAIN_SIZE)+'_'+str(REP_ID)+'_'\n",
    "\n",
    "    with open(filename+'f1_score.pickle', 'wb') as f:\n",
    "        pickle.dump([macro, micro, cm], f)\n",
    "    with open(filename+'softmax.pickle', 'wb') as f:\n",
    "        pickle.dump([y_trnval_hat, y_tst_hat], f)\n",
    "\n",
    "    print('model_id:', MODEL_ID,\n",
    "          'train size:', TRAIN_SIZE,\n",
    "          'rep_id:', REP_ID,\n",
    "          'macro:', np.round(macro, 4), \n",
    "          'micro:', np.round(micro, 4),\n",
    "          'labels:', len(labels),\n",
    "          'epochs:', len(log.history['loss']))\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
